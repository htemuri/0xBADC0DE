---
title: HFT SRE Roadmap with Timelines & Task Checkboxes
date: 2014/04/02
author: Harris Temuri
---

Below is a **phased approach** with approximate durations and **checklist-style tasks**. Each phase focuses on a core subject area, with recommended **reading tasks** and **project tasks**. Mark tasks as complete by replacing `- [ ]` with `- [x]` once done.

---

## **Phase 1: Computer Architecture & Basics (3–4 Weeks)**

### Duration
- **Estimated Time**: 3–4 weeks

### Reading Tasks
- [ ] **Read** “Computer Architecture: A Quantitative Approach” (Hennessy & Patterson)
- [ ] **Skim** CPU-related sections in “Systems Performance” (Brendan Gregg)

### Project Tasks
- [ ] **CPU Cache Benchmarking**  
  - Write a C/C++ program to measure performance for arrays sized to fit/unfit L1/L2/L3 caches  
  - Use `perf` or `cachegrind` to collect data on cache misses and branch mispredictions
- [ ] **NUMA-Aware Memory Allocation**  
  - Use `numactl` to bind processes to a specific NUMA node  
  - Benchmark memory throughput/latency with `mbw` or `lmbench`

**Milestones**  
- [ ] You have logs/graphs showing cache and NUMA performance differences  
- [ ] You understand branch prediction, cache hierarchies, and NUMA basics

---

## **Phase 2: Operating Systems & Kernel Tuning (3–4 Weeks)**

### Duration
- **Estimated Time**: 3–4 weeks

### Reading Tasks
- [ ] **Read** “Operating System Concepts” (Silberschatz, Galvin, Gagne)
- [ ] **Study** “Linux Kernel Development” (Robert Love) chapters on scheduling, memory management

### Project Tasks
- [ ] **Custom Low-Latency Kernel**  
  - Compile a **PREEMPT_RT**-patched kernel  
  - Use `cyclictest` to measure real-time scheduling improvements
- [ ] **Syscall Profiling & Minimization**  
  - Use `strace` or eBPF to measure syscall overhead  
  - Implement a ring buffer in userspace; compare performance with `read()/write()`

**Milestones**  
- [ ] You can explain how different schedulers impact latency  
- [ ] You have a working RT kernel with documented latency gains

---

## **Phase 3: Networking & Low-Latency Optimization (4–6 Weeks)**

### Duration
- **Estimated Time**: 4–6 weeks

### Reading Tasks
- [ ] **Read** “TCP/IP Illustrated” Vol. 1 (W. Richard Stevens)
- [ ] **Review** DPDK or Solarflare Onload documentation

### Project Tasks
- [ ] **UDP Multicast Feed Handler**  
  - Configure **multicast** on your MikroTik router  
  - Write a small C++/Python listener; measure packet drops/jitter with `tcpdump` or Wireshark
- [ ] **Kernel Bypass Experiment (DPDK)**  
  - Install/configure **DPDK** on a Dell server  
  - Compare packet throughput/latency to standard Linux sockets
- [ ] **MikroTik Router Tuning**  
  - Enable **hardware offload** if supported  
  - Benchmark performance with iPerf or netperf

**Milestones**  
- [ ] You have measured **round-trip latency** for standard vs. bypass networking  
- [ ] You can explain **TCP congestion control** or **UDP multicast** in depth

---

## **Phase 4: Observability & Monitoring (3–4 Weeks)**

### Duration
- **Estimated Time**: 3–4 weeks

### Reading Tasks
- [ ] **Read** “Prometheus: Up & Running” (Brian Brazil)
- [ ] **Study** “BPF Performance Tools” (Brendan Gregg) for eBPF

### Project Tasks
- [ ] **Prometheus & Grafana Setup**  
  - Deploy Prometheus on a central server; configure scrapers on all lab nodes  
  - Create **Grafana dashboards** for CPU usage, network latency, disk I/O
- [ ] **Real-Time Logging Pipeline**  
  - Configure Fluent Bit or Logstash for log ingestion  
  - Use **structured JSON logging** for easier correlation
- [ ] **eBPF Tracing**  
  - Write bpftrace scripts to measure system call latency or packet flow  
  - Investigate kernel-level performance bottlenecks in real time

**Milestones**  
- [ ] You have real-time alerts for latency spikes above a certain threshold  
- [ ] You can debug system issues using logs, metrics, and eBPF traces

---

## **Phase 5: High-Performance Programming & Concurrency (4–6 Weeks)**

### Duration
- **Estimated Time**: 4–6 weeks

### Reading Tasks
- [ ] **Read** “The Art of Multiprocessor Programming” (Herlihy & Shavit)
- [ ] **Review** “Effective C++” (Scott Meyers) for C++ best practices

### Project Tasks
- [ ] **Lock-Free Ring Buffer**  
  - Implement a **single-producer, single-consumer** ring buffer using std::atomic  
  - Benchmark throughput under different concurrency scenarios
- [ ] **High-Performance Order Book Simulation**  
  - Write a **multi-threaded** order-matching engine in C++  
  - Focus on **cache alignment** to avoid false sharing
- [ ] **Parallel Data Processing**  
  - Parse large data files in parallel using **OpenMP** or **std::thread**  
  - Profile concurrency overhead with `perf` or Intel VTune

**Milestones**  
- [ ] You understand how to avoid **race conditions** and false sharing  
- [ ] You can measure concurrency performance (messages/sec, CPU usage, etc.)

---

## **Phase 6: Hardware Acceleration & FPGA/Electronics (4–6 Weeks)**

### Duration
- **Estimated Time**: 4–6 weeks

### Reading Tasks
- [ ] **Read** “FPGA Prototyping by VHDL Examples” (Pong P. Chu) or Verilog resources
- [ ] **Check** Intel, Xilinx, Mellanox whitepapers on low-latency networking

### Project Tasks
- [ ] **Precision Time Protocol (PTP) Setup**  
  - Configure PTP on your MikroTik router and Dell servers  
  - Compare **nanosecond-level** sync vs. NTP
- [ ] **FPGA-Based Timestamping** (If FPGA board available)  
  - Implement a basic **packet timestamping** module  
  - Measure real-world latency with your **oscilloscope**
- [ ] **NIC Offload & Kernel Bypass**  
  - Experiment with **Solarflare Onload** or **Mellanox OFED** drivers  
  - Compare microsecond-level latency improvements over standard networking

**Milestones**  
- [ ] You have sub-millisecond or microsecond-level timing accuracy across your lab  
- [ ] You have hands-on experience with an FPGA or advanced NIC offloads

---

# Sample Timeline Overview

| **Month** | **Focus**                                                                      | **Deliverables**                                                 |
|-----------|--------------------------------------------------------------------------------|------------------------------------------------------------------|
| Month 1   | Phase 1 (Computer Architecture) + Begin Phase 2 (OS & Kernel Tuning)           | Cache Benchmarks, NUMA Tests, RT Kernel Build                    |
| Month 2   | Complete Phase 2 (OS & Kernel Tuning) + Start Phase 3 (Networking)             | PREEMPT_RT Kernel, Syscall Profiling, DPDK Experiments           |
| Month 3   | Continue Phase 3 (Networking) + Phase 4 (Observability & Monitoring)           | Low-Latency Router Config, Prometheus + Grafana Dashboards       |
| Month 4   | Complete Phase 4 (Observability) + Start Phase 5 (High-Performance Programming)| eBPF Tracing, Lock-Free Ring Buffer                              |
| Month 5   | Continue Phase 5 (Concurrency) + Begin Phase 6 (Hardware Acceleration)         | Multi-threaded Order Book, PTP Setup                             |
| Month 6+  | Finish Phase 6 (FPGA/Electronics) & Deepen Any Area                            | NIC Offload Projects, FPGA Timestamping, Final Optimizations     |

---

## **Final Tips**

1. **Documentation**:  
   - [ ] Keep a personal wiki or GitHub repo with **before/after benchmarks**, detailed logs, and config files.  
2. **Iteration**:  
   - [ ] Revisit earlier phases with new insights (e.g., re-optimize Phase 1 code after learning concurrency in Phase 5).  
3. **Hands-On**:  
   - [ ] Emphasize **real metrics** (latency in microseconds, throughput in messages/sec) to demonstrate improvements.  
4. **Portfolio**:  
   - [ ] Showcase completed tasks and learned skills in interviews or on a personal website.

Good luck on your **HFT SRE** journey!
